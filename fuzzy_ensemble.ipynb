{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uyenphl/fetal-echocardiogram/blob/main/fuzzy_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPQHF1UNUuPI"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVNpXxrMmll-",
        "outputId": "75de1c2e-33d6-41da-cd52-3bd1a71c6dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1hZGACyj1-8",
        "outputId": "58824b82-b0ff-4ff5-fecb-55f9e258f70e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'3class (normal, 4CV, 3VT).gdoc'   Cardiac_Original.zip\n",
            " Cardiac_General.zip\t\t   output.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/MasterThesis/Colab Model/Data/\"\n",
        "!unzip -q \"/content/drive/MyDrive/MasterThesis/Colab Model/Data/Cardiac_General.zip\"\n",
        "!mv /content/Cardiac_General/3VT /content/Cardiac_General/3VTV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmT1k9NbVj65"
      },
      "source": [
        "#Setup Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7KHIzO8siqV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn import model_selection\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7o7frJbSsDC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example: if your folder is in MyDrive/Images\n",
        "data_dir = '/content/Cardiac_General'\n",
        "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extractor Baselearner"
      ],
      "metadata": {
        "id": "xHu1koml3VqD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX5eIIntN2cA"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "def augment(path,IMG_DIM):\n",
        "\n",
        "  datagen = ImageDataGenerator(rotation_range=40,width_shift_range=.2,height_shift_range=.2,shear_range=.2,zoom_range=.2,horizontal_flip=True,fill_mode='nearest')\n",
        "  directories = os.listdir(path)\n",
        "  files_path = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(len(directories)):\n",
        "    ls = []\n",
        "    curPath = path +'/' +directories[i] + '/*'\n",
        "    ls = glob.glob(curPath)\n",
        "    temp = []\n",
        "    for img in ls:\n",
        "      x = img_to_array(load_img(img,target_size = IMG_DIM))\n",
        "      x = x.reshape((1,)+x.shape)\n",
        "      temp.append(x)\n",
        "    i = 0\n",
        "    target = 800\n",
        "    for batch in datagen.flow(temp,batch_size=4,save_to_dir=curPath[:-1],save_format='jpg'):\n",
        "      i += 1\n",
        "      if len(ls) + i*4>800:\n",
        "        break\n",
        "\n",
        "#Creating Frame\n",
        "def createFrame(path,IMG_DIM):\n",
        "  train_imgs = []\n",
        "  labels = []\n",
        "  directories = os.listdir(path)\n",
        "  for i in range(len(directories)):\n",
        "    ls = []\n",
        "    temp = []\n",
        "    curPath = path +'/' +directories[i] + '/*'\n",
        "    ls = glob.glob(curPath)\n",
        "    for img in ls:\n",
        "      x = img_to_array(load_img(img,target_size = IMG_DIM))\n",
        "      temp.append(x)\n",
        "\n",
        "    train_imgs  = train_imgs + temp\n",
        "    label = []\n",
        "    label = [i]*len(ls)\n",
        "    labels += label\n",
        "\n",
        "  df = pd.DataFrame(list(zip(train_imgs,labels)))\n",
        "  df = df.sample(frac = 1)\n",
        "  return df\n",
        "\n",
        "def kFold(df):\n",
        "\n",
        "  df['kfold'] = -1\n",
        "  df = df.reset_index(drop=True)\n",
        "  y = df[1]\n",
        "  kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "  for f,(t_,v_) in enumerate(kf.split(X=df,y=y)):\n",
        "    df.loc[v_,'kfold'] = f\n",
        "\n",
        "  return df\n",
        "\n",
        "#Customized CNN models\n",
        "def DenseNet169(train_imgs,train_labels,class_no,num_epochs=10):\n",
        "  print(\"-------------------------------------DenseNet-169--------------------------------------------\")\n",
        "  input_shape_densenet = (224, 224, 3)\n",
        "  densenet_model1 = keras.applications.DenseNet169(include_top=False,weights=\"imagenet\",input_tensor=None,input_shape=input_shape_densenet,pooling=None)\n",
        "  densenet_model1.trainable = True\n",
        "  for layer in densenet_model1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  layer = keras.layers.Flatten()(densenet_model1.output)\n",
        "  layer = keras.layers.Dense(units=512,activation='relu')(layer)\n",
        "  layer = keras.layers.Dropout(0.2)(layer)\n",
        "  layer = keras.layers.Dense(units=128,activation='relu')(layer)\n",
        "  layer = keras.layers.Dense(units=class_no,activation='softmax')(layer)\n",
        "  model1 = keras.models.Model(densenet_model1.input, outputs=layer)\n",
        "  model1.compile(optimizer = keras.optimizers.RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  history = model1.fit(x=train_imgs,y=train_labels, epochs = num_epochs, batch_size = 32, verbose=0, validation_split=0.2)\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy of DenseNet-169')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  print(\"------------------------------------------------------------------------------------------\")\n",
        "  return model1\n",
        "\n",
        "def VGG16(train_imgs,train_labels,class_no,num_epochs=10):\n",
        "  print(\"-------------------------------------VGG16---------------------------------------------\")\n",
        "  pre_trained_model2 = keras.applications.VGG16(input_shape = (224,224,3), include_top=False,weights=\"imagenet\")\n",
        "  for layer in pre_trained_model2.layers:\n",
        "    layer.trainable = False\n",
        "  x = keras.layers.Flatten()(pre_trained_model2.output)\n",
        "  x = layers.Dense(1024,activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(64,activation='relu')(x)\n",
        "  x = layers.Dense(class_no,activation='softmax')(x)\n",
        "  model2 = Model(pre_trained_model2.input,x)\n",
        "  model2.compile(optimizer = RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  history = model2.fit(x=train_imgs,y=train_labels, epochs = num_epochs, batch_size = 32, verbose=0, validation_split=0.2)\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy of Xception')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  print(\"------------------------------------------------------------------------------------------\")\n",
        "  return model2\n",
        "\n",
        "def Xception(train_imgs,train_labels,class_no,num_epochs=10):\n",
        "  print(\"-------------------------------------XCEPTION---------------------------------------------\")\n",
        "  pre_trained_model3 = keras.applications.Xception(input_shape = (224,224,3), include_top=False,weights=\"imagenet\")\n",
        "  for layer in pre_trained_model3.layers:\n",
        "    layer.trainable = False\n",
        "  x = keras.layers.Flatten()(pre_trained_model3.output)\n",
        "  x = layers.Dense(102,activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(32,activation='relu')(x)\n",
        "  x = layers.Dense(class_no,activation='softmax')(x)\n",
        "  model3 = Model(pre_trained_model3.input,x)\n",
        "  model3.compile(optimizer = RMSprop(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['acc'])\n",
        "  history = model3.fit(x=train_imgs,y=train_labels, epochs = num_epochs, batch_size = 32, verbose=0, validation_split=0.2)\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy of Xception')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  print(\"------------------------------------------------------------------------------------------\")\n",
        "  return model3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkGNGq2gmZNd"
      },
      "source": [
        "# Generate Fuzzy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63JFsAuaJ3Mr"
      },
      "outputs": [],
      "source": [
        "#Fuzzy Rank-based Ensemble:\n",
        "def getScore(model,test_imgs):\n",
        "  res = model.predict(test_imgs)\n",
        "  return res\n",
        "\n",
        "def generateRank1(score,class_no):\n",
        "  rank = np.zeros([class_no,1])\n",
        "  scores = np.zeros([class_no,1])\n",
        "  scores = score\n",
        "  for i in range(class_no):\n",
        "      rank[i] = 1 - np.exp(-((scores[i]-1)**2)/2.0)\n",
        "  return rank\n",
        "\n",
        "def generateRank2(score,class_no):\n",
        "  rank = np.zeros([class_no,1])\n",
        "  scores = np.zeros([class_no,1])\n",
        "  scores = score\n",
        "  for i in range(class_no):\n",
        "      rank[i] = 1 - np.tanh(((scores[i]-1)**2)/2)\n",
        "  return rank\n",
        "\n",
        "def generateRank3(score,class_no):\n",
        "  rank = np.zeros([class_no,1])\n",
        "  scores = np.zeros([class_no,1])\n",
        "  scores = score\n",
        "  for i in range(class_no):\n",
        "      rank[i] = 1/(1+(np.exp(-scores[i])))\n",
        "  return rank\n",
        "\n",
        "def doFusion(res1,res2,res3,label,class_no):\n",
        "  cnt = 0\n",
        "  id = []\n",
        "  print(class_no)\n",
        "  for i in range(len(res1)):\n",
        "      rank1 = generateRank1(res1[i],class_no)*generateRank2(res1[i],class_no)\n",
        "      rank2 = generateRank1(res2[i],class_no)*generateRank2(res2[i],class_no)\n",
        "      rank3 = generateRank1(res3[i],class_no)*generateRank2(res3[i],class_no)\n",
        "      rankSum = rank1 + rank2 + rank3\n",
        "      rankSum = np.array(rankSum)\n",
        "      scoreSum = 1 - (res1[i] + res2[i] + res3[i])/3\n",
        "      scoreSum = np.array(scoreSum)\n",
        "\n",
        "      fusedScore = (rankSum.T)*scoreSum\n",
        "      cls = np.argmin(rankSum)\n",
        "      if cls<class_no and label[i][cls]== 1:\n",
        "          cnt += 1\n",
        "      id.append(cls)\n",
        "  print(\"doFusion Score\")\n",
        "  print(cnt/len(res1))\n",
        "  return id\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfFeYCQVmogV"
      },
      "source": [
        "# Fuzzy Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vBwGstVShYbL"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_directory', type=str, default = '.', help='Directory where the image data is stored')\n",
        "parser.add_argument('--epochs', type=int, default = 10, help='Number of Epochs of training')\n",
        "\n",
        "args = parser.parse_args(['--data_directory', '/content/Cardiac_General', '--epochs', '10'])\n",
        "\n",
        "path1 = args.data_directory\n",
        "num_epochs = args.epochs\n",
        "\n",
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT,3)\n",
        "\n",
        "df = createFrame(path1,IMG_DIM)\n",
        "df = kFold(df)\n",
        "\n",
        "target_names = os.listdir(path1)\n",
        "num_classes = len(target_names)\n",
        "\n",
        "for i in range(1,6):\n",
        "  print(f\"----------------------------------------------------FOLD NO {i}-------------------------------------------------------\")\n",
        "  dfTrain = df[df['kfold']!=i]\n",
        "  dfTest = df[(df['kfold']==i)]\n",
        "  train_imgs = list(dfTrain[0])\n",
        "  train_imgs = np.array(train_imgs)\n",
        "  train_imgs = train_imgs/255\n",
        "  train_labels = np.array(dfTrain[1])\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(train_labels)\n",
        "  train_labels = encoder.transform(train_labels)\n",
        "  train_labels = to_categorical(train_labels)\n",
        "\n",
        "  test_imgs = list(dfTest[0])\n",
        "  test_imgs = np.array(test_imgs)\n",
        "  test_imgs = test_imgs/255\n",
        "  test_labels = np.array(dfTest[1])\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(test_labels)\n",
        "  test_labels = encoder.transform(test_labels)\n",
        "  test_labels = to_categorical(test_labels)\n",
        "\n",
        "  # Define target names as requested\n",
        "  target_names = ['Normal', '4CV', '3VTV']\n",
        "  annot_font_size = 14\n",
        "  annot_kws = {\"size\": annot_font_size}\n",
        "\n",
        "  model1 = DenseNet169(train_imgs,train_labels,class_no=num_classes,num_epochs=10)\n",
        "  model2 = VGG16(train_imgs,train_labels,class_no=num_classes,num_epochs=10)\n",
        "  model3 = Xception(train_imgs,train_labels,class_no=num_classes,num_epochs=10)\n",
        "\n",
        "  print(\"BASE LEARNERS ACCURACY-----------1.DenseNet169 2.VGG16 3.Xception\")\n",
        "  model1.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "  model2.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "  model3.evaluate(test_imgs, test_labels, batch_size=32)\n",
        "\n",
        "  res1 = model1.predict(test_imgs)\n",
        "  res2 = model2.predict(test_imgs)\n",
        "  res3 = model3.predict(test_imgs)\n",
        "  predictedClass = doFusion(res1,res2,res3,test_labels,class_no=num_classes)\n",
        "\n",
        "  prob1 = np.max(res1,axis=-1)\n",
        "  prob2 = np.max(res2,axis=-1)\n",
        "  prob3 = np.max(res3,axis=-1)\n",
        "\n",
        "  leb1 = np.argmax(res1,axis=-1)\n",
        "  leb2 = np.argmax(res2,axis=-1)\n",
        "  leb3 = np.argmax(res3,axis=-1)\n",
        "  actual = np.argmax(test_labels,axis=-1)\n",
        "\n",
        "  cm_model1 = confusion_matrix(actual, leb1)\n",
        "  cm_model2 = confusion_matrix(actual, leb2)\n",
        "  cm_model3 = confusion_matrix(actual, leb3)\n",
        "  cm_ensemble = confusion_matrix(actual, predictedClass)\n",
        "\n",
        "  print('DenseNet169 base learner')\n",
        "  print(classification_report(actual, leb1,target_names = target_names,digits=4))\n",
        "  plt.figure(figsize=(18, 10))\n",
        "  plt.subplot(2,3,1)\n",
        "  sns.heatmap(cm_model1, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names, annot_kws=annot_kws)\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.title('Confusion Matrix - DenseNet169')\n",
        "  print('VGG16 base learner')\n",
        "  print(classification_report(actual, leb2,target_names = target_names,digits=4))\n",
        "  plt.subplot(2, 3, 2)\n",
        "  sns.heatmap(cm_model2, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names, annot_kws=annot_kws)\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.title('Confusion Matrix - VGG16')\n",
        "  print('XCeption base learner')\n",
        "  print(classification_report(actual, leb3,target_names = target_names,digits=4))\n",
        "  plt.subplot(2, 3, 4)\n",
        "  sns.heatmap(cm_model3, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names, annot_kws=annot_kws)\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.title('Confusion Matrix - XCeption')\n",
        "\n",
        "  print('Ensembled')\n",
        "  print(classification_report(actual, predictedClass,target_names = target_names,digits=4))\n",
        "  plt.subplot(2, 3, 5)\n",
        "  sns.heatmap(cm_ensemble, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names, annot_kws=annot_kws)\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.title('Confusion Matrix - Ensemble')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"--------------------------------------------------END OF FOLD NO {i}--------------------------------------------------------\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}